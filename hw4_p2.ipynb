{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_ensemble(X_train, y_train, X_test, y_test, n_clf = 10):\n",
    "    '''\n",
    "    Returns accuracy on the test set X_test with corresponding labels y_test\n",
    "    using a bagging ensemble classifier with n_clf decision trees trained with \n",
    "    training examples X_train and training labels y_train.\n",
    "    Input:\n",
    "        X_train- (n_train, d) array of training feature vectors, where n_train \n",
    "            is # of examples and d is # of features\n",
    "        y_train- (n_train, ) array of labels corresponding to X_train\n",
    "        X_test- (n_test, d) array of testing feature vectors, where n_test is \n",
    "            # of examples and d is # of features\n",
    "        y_test- (n_test, ) array of labels corresponding to X_test\n",
    "        n_clf- # of decision tree classifiers in the bagging ensemble, default\n",
    "            value of n_clf is 10\n",
    "    Output:\n",
    "        Accuracy of the bagging ensemble classifier on X_test\n",
    "    '''\n",
    "    \n",
    "    # ---------- TODO make your implementation here---------------\n",
    "    skf = StratifiedKFold()\n",
    "    model = DecisionTreeClassifier()\n",
    "\n",
    "    return accuracy\n",
    "    # -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, y_train, X_test, y_test, m, n_clf = 10):\n",
    "    '''\n",
    "    Returns accuracy on the test set X_test with corresponding labels y_test\n",
    "    using a random forest classifier with n_clf decision trees trained with \n",
    "    training examples X_train and training labels y_train.\n",
    "    Input:\n",
    "        X_train- (n_train, d) array of training feature vectors, where n_train \n",
    "            is # of examples and d is # of features\n",
    "        y_train- (n_train, ) array of labels corresponding to X_train\n",
    "        X_test- (n_test, d) array of testing feature vectors, where n_test is \n",
    "            # of examples and d is # of features\n",
    "        y_test- (n_test, ) array of labels corresponding to X_test\n",
    "        n_clf- # decision tree classifiers in the random forest, default\n",
    "            value of n_clf is 10\n",
    "    Output:\n",
    "        Accuracy of the random forest classifier on X_test\n",
    "    '''\n",
    "\n",
    "    # ---------- TODO make your implementation here---------------\n",
    "    return accuracy\n",
    "    # -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(pred_list):\n",
    "    '''\n",
    "    Given a list of m (n, ) arrays, each (n, ) array containing the predictions for \n",
    "    same set of n examples (using different classifiers), return a (n, ) array \n",
    "    containing majority vote prediction of the m (n, ) arrays\n",
    "    Input:\n",
    "        pred_list- a list of m (n, ) arays\n",
    "    Output:\n",
    "        y_pred- (n, ) array containing majority vote prediction using pred_list\n",
    "    ''' \n",
    "    # ---------- TODO make your implementation here---------------\n",
    "    return y_pred\n",
    "    # -------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(random_forest_scores, bagging_scores):\n",
    "    '''\n",
    "    Plots histogram of values in random_forest_scores and bagging_scores\n",
    "    overlayed on top of each other\n",
    "    Input:\n",
    "        random_forest_scores- a list containing accuracy values for random forest classifier \n",
    "        for 100 different train and test set splits\n",
    "        bagging_scores- a list containing accuracy values for bagging ensemble classifier \n",
    "        using decision trees for the same 100 different train and test set splits\n",
    "        as random_forest_scores\n",
    "    '''\n",
    "    bins = np.linspace(0.8, 1.0, 100)\n",
    "    plt.figure()\n",
    "    plt.hist(random_forest_scores, bins, alpha=0.5, label='random forest')\n",
    "    plt.hist(bagging_scores, bins, alpha=0.5, label='bagging')\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31380\\2505359173.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mrandom_forest_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_forest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mbagging_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbagging_ensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mresults1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_forest_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31380\\3448850233.py\u001b[0m in \u001b[0;36mrandom_forest\u001b[1;34m(X_train, y_train, X_test, y_test, m, n_clf)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# ---------- TODO make your implementation here---------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;31m# -------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "# Load digits dataset\n",
    "digits = load_digits(n_class = 4)\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Calculate accuracy of bagging ensemble and random forest for 100 random train/test splits\n",
    "# Analyze how the performance of bagging & random forest changes with m\n",
    "results1, results2 = [], []\n",
    "for j in range(0, 64, 2):\n",
    "    print(j)\n",
    "    bagging_scores, random_forest_scores = [], []\n",
    "    for i in range(100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "        random_forest_scores.append(random_forest(X_train, y_train, X_test, y_test, j+1))\n",
    "        bagging_scores.append(bagging_ensemble(X_train, y_train, X_test, y_test))\n",
    "    results1.append(np.median(np.array(random_forest_scores)))\n",
    "    results2.append(np.median(np.array(bagging_scores)))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(0, 64, 2), results1, '--', label = 'random forest')\n",
    "plt.plot(range(0, 64, 2), results2, '--', label = 'bagging')\n",
    "plt.xlabel('m')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "e320dfeb06630bafa77eb5da607544aa614fc900b2e00ab41ad317ff9ada1530"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
